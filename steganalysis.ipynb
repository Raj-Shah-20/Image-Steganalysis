{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":19991,"databundleVersionId":1117522,"sourceType":"competition"},{"sourceId":7060876,"sourceType":"datasetVersion","datasetId":4064909},{"sourceId":2645,"sourceType":"modelInstanceVersion","modelInstanceId":1911}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n# import matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import models, layers\nfrom keras.layers import DepthwiseConv2D,SeparableConv2D,Conv2D,MaxPool2D,Dense,GlobalMaxPool2D,Flatten,Input,Add,BatchNormalization,GlobalAveragePooling2D,ReLU,Dropout,AveragePooling2D\nimport warnings\nfrom sklearn import metrics\nwarnings.filterwarnings(\"ignore\")\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:40:15.343715Z","iopub.execute_input":"2023-12-01T22:40:15.344611Z","iopub.status.idle":"2023-12-01T22:40:26.538045Z","shell.execute_reply.started":"2023-12-01T22:40:15.344568Z","shell.execute_reply":"2023-12-01T22:40:26.537307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(cv2.imread(\"/kaggle/input/alaska2-image-steganalysis/Cover/00001.jpg\"))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:40:26.539341Z","iopub.execute_input":"2023-12-01T22:40:26.539807Z","iopub.status.idle":"2023-12-01T22:40:26.543124Z","shell.execute_reply.started":"2023-12-01T22:40:26.539779Z","shell.execute_reply":"2023-12-01T22:40:26.542349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configure Strategy. Assume TPU...if not set default for GPU/CPU\ntpu = None\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    # Enable XLA\n    tf.config.optimizer.set_jit(enabled = \"autoclustering\")\n    strategy = tf.distribute.get_strategy()\n    \n# Set Auto Tune\nAUTOTUNE = tf.data.experimental.AUTOTUNE \nBATCH_SIZE = 16 * strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:40:26.544060Z","iopub.execute_input":"2023-12-01T22:40:26.544370Z","iopub.status.idle":"2023-12-01T22:40:35.416571Z","shell.execute_reply.started":"2023-12-01T22:40:26.544338Z","shell.execute_reply":"2023-12-01T22:40:35.415701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir=\"/kaggle/input/alaska2-image-steganalysis/\"","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:40:35.422258Z","iopub.execute_input":"2023-12-01T22:40:35.422518Z","iopub.status.idle":"2023-12-01T22:40:35.432212Z","shell.execute_reply.started":"2023-12-01T22:40:35.422479Z","shell.execute_reply":"2023-12-01T22:40:35.431541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Creation","metadata":{}},{"cell_type":"code","source":"def append_path(pre):\n    return np.vectorize(lambda file: os.path.join(\"/kaggle/input/alaska2-image-steganalysis/\", pre, file))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:40:35.432994Z","iopub.execute_input":"2023-12-01T22:40:35.433300Z","iopub.status.idle":"2023-12-01T22:40:35.440441Z","shell.execute_reply.started":"2023-12-01T22:40:35.433269Z","shell.execute_reply":"2023-12-01T22:40:35.439765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_filenames = np.array(os.listdir(\"/kaggle/input/alaska2-image-steganalysis/Cover\"))\nnp.random.seed(0)\npositives = train_filenames.copy()\nnegatives = train_filenames.copy()\nnp.random.shuffle(positives)\nnp.random.shuffle(negatives)\n\njmipod = append_path('JMiPOD')(positives[10000:15000])\njuniward = append_path('JUNIWARD')(positives[15000:20000])\nuerd = append_path('UERD')(positives[20000:25000])\nneg_path = append_path('Cover')(negatives[:15000])\npos_path=np.concatenate([jmipod,juniward,uerd])\nnp.random.shuffle(pos_path)\ntrain_paths=np.concatenate([neg_path,pos_path])\n\n# test_paths=np.concatenate([append_path('JMiPOD')(positives[100:200]),append_path('JUNIWARD')(positives[200:300])],append_path('UERD')(positives[300:400]),append_path('Cover')(positives[400:500]))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:40:35.441217Z","iopub.execute_input":"2023-12-01T22:40:35.441479Z","iopub.status.idle":"2023-12-01T22:40:35.955506Z","shell.execute_reply.started":"2023-12-01T22:40:35.441453Z","shell.execute_reply":"2023-12-01T22:40:35.954618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.shuffle(train_paths)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:40:35.956541Z","iopub.execute_input":"2023-12-01T22:40:35.956832Z","iopub.status.idle":"2023-12-01T22:40:35.962388Z","shell.execute_reply.started":"2023-12-01T22:40:35.956807Z","shell.execute_reply":"2023-12-01T22:40:35.961595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_paths","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:40:35.963234Z","iopub.execute_input":"2023-12-01T22:40:35.963472Z","iopub.status.idle":"2023-12-01T22:40:35.974712Z","shell.execute_reply.started":"2023-12-01T22:40:35.963448Z","shell.execute_reply":"2023-12-01T22:40:35.973991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels=[]\nfor path in train_paths:\n    if \"Cover\" in path:\n        train_labels.append(0)\n    else:\n        train_labels.append(1)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:40:35.976828Z","iopub.execute_input":"2023-12-01T22:40:35.977067Z","iopub.status.idle":"2023-12-01T22:40:35.994810Z","shell.execute_reply.started":"2023-12-01T22:40:35.977042Z","shell.execute_reply":"2023-12-01T22:40:35.994082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_labels),len(train_paths)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:40:35.995624Z","iopub.execute_input":"2023-12-01T22:40:35.995885Z","iopub.status.idle":"2023-12-01T22:40:36.001481Z","shell.execute_reply.started":"2023-12-01T22:40:35.995858Z","shell.execute_reply":"2023-12-01T22:40:36.000896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_augment(image,label=None):\n    image=tf.image.random_flip_left_right(image)\n    image=tf.image.random_flip_up_down(image)\n    \n    if label is None:\n        return image\n    else:\n        return image,label\n    \ndef decode_image(filename, label=None, image_size=(256,256)):\n    bits=tf.io.read_file(filename)\n    image=tf.image.decode_jpeg(bits,channels=3)\n    image = tf.image.rgb_to_grayscale(image)\n    image=tf.cast(image,tf.float32) / 255.0#image to tf.float32 data type\n    image=tf.image.resize(image,image_size)\n    \n    if label is None:\n        return data_augment(image)\n    else:\n        return data_augment(image,label)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:46:39.875699Z","iopub.execute_input":"2023-12-01T22:46:39.876267Z","iopub.status.idle":"2023-12-01T22:46:39.883196Z","shell.execute_reply.started":"2023-12-01T22:46:39.876214Z","shell.execute_reply":"2023-12-01T22:46:39.882244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset=np.concatenate([append_path('Cover')(negatives[50000:51000]),append_path('UERD')(positives[51000:52000])])","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:46:41.938305Z","iopub.execute_input":"2023-12-01T22:46:41.938689Z","iopub.status.idle":"2023-12-01T22:46:41.947170Z","shell.execute_reply.started":"2023-12-01T22:46:41.938656Z","shell.execute_reply":"2023-12-01T22:46:41.946182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_label=np.array([0] * len(append_path('Cover')(negatives[50000:51000]))+[1] * len(append_path('UERD')(positives[51000:52000])))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:46:42.668715Z","iopub.execute_input":"2023-12-01T22:46:42.669140Z","iopub.status.idle":"2023-12-01T22:46:42.677589Z","shell.execute_reply.started":"2023-12-01T22:46:42.669105Z","shell.execute_reply":"2023-12-01T22:46:42.676643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_label","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:46:44.778302Z","iopub.execute_input":"2023-12-01T22:46:44.778699Z","iopub.status.idle":"2023-12-01T22:46:44.785315Z","shell.execute_reply.started":"2023-12-01T22:46:44.778665Z","shell.execute_reply":"2023-12-01T22:46:44.784141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_validation, y_train, y_validation = train_test_split(train_paths, train_labels, test_size=0.15, random_state=1000)\n\n# def decode_image(filename, label=None, image_size=(256,256)):\n#     bits=tf.io.read_file(filename)\n#     image=tf.image.decode_jpeg(bits,channels=3)\n# #     image = tf.image.rgb_to_grayscale(image)\n#     image=tf.cast(image,tf.float32) / 255.0#image to tf.float32 data type\n#     image=tf.image.resize(image,image_size)\n    \n#     if label is None:\n#         return image\n#     else:\n#         return image,label\n    \n    \ntrain_dataset = (tf.data.Dataset\n                 .from_tensor_slices((x_train,y_train))\n                 .map(decode_image, num_parallel_calls=AUTOTUNE)\n                 .cache()\n                 .repeat()\n                 .shuffle(1024)\n                 .batch(BATCH_SIZE)\n                 .prefetch(AUTOTUNE)\n                )\nvalid_dataset= (tf.data.Dataset\n                .from_tensor_slices((x_validation,y_validation))\n                .map(decode_image, num_parallel_calls=AUTOTUNE)\n                .batch(BATCH_SIZE)\n                .prefetch(AUTOTUNE)\n\n               )\ntest= (tf.data.Dataset\n                .from_tensor_slices((test_dataset))\n                .map(decode_image, num_parallel_calls=AUTOTUNE)\n                .batch(BATCH_SIZE)\n                .prefetch(AUTOTUNE)\n\n               )\n\n# def load_image(filename,label):\n#     img=cv2.imread(filename)\n#     img=cv2.resize(img,(256,256))\n#     img=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n#     img=img/255.0\n#     return img,label\n\n# test_dataset= (tf.data.Dataset\n#                .from_tensor_slices(test_paths)\n#                .map(decode_image, num_parallel_calls=AUTO)\n#                .batch(BATCH_SIZE)\n#               )\n\nclass CustomImageDataset(tf.keras.utils.Sequence):\n    def __init__(self, file_paths, labels, batch_size):\n        self.file_paths = file_paths\n        self.labels = labels\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(self.file_paths))\n\n    def __len__(self):\n        return int(np.ceil(len(self.file_paths) / self.batch_size))\n\n    def __getitem__(self, index):\n        start = index * self.batch_size\n        end = (index + 1) * self.batch_size\n        batch_file_paths = self.file_paths[start:end]\n        batch_labels = self.labels[start:end]\n\n        images = [self.decode_image(file_path) for file_path in batch_file_paths]\n        images = np.array(images)\n\n        return images, np.array(batch_labels)\n    \n    \n    def decode_image(self,filename, label=None, image_size=(256,256)):\n        bits=tf.io.read_file(filename)\n        image=tf.image.decode_jpeg(bits,channels=3)\n        image = tf.image.rgb_to_grayscale(image)\n        image=tf.cast(image,tf.float32) / 255.0#image to tf.float32 data type\n        image=tf.image.resize(image,image_size)\n\n        if label is None:\n            return self.data_augment(image)\n        else:\n            return self.data_augment(image,label)\n\n    def data_augment(self,image,label=None):\n        image=tf.image.random_flip_left_right(image)\n        image=tf.image.random_flip_up_down(image)\n\n        if label is None:\n            return image\n        else:\n            return image,label\n\n\nbatch_size = 32\ntarget_size = (512,512,3)\n\n\ntrain = CustomImageDataset(x_train, y_train, batch_size=BATCH_SIZE)\nvalidation=CustomImageDataset(x_validation,y_validation,batch_size=BATCH_SIZE)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:46:45.539640Z","iopub.execute_input":"2023-12-01T22:46:45.540066Z","iopub.status.idle":"2023-12-01T22:46:45.905789Z","shell.execute_reply.started":"2023-12-01T22:46:45.540033Z","shell.execute_reply":"2023-12-01T22:46:45.904623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNetB7","metadata":{"execution":{"iopub.status.busy":"2023-11-25T16:59:04.466284Z","iopub.execute_input":"2023-11-25T16:59:04.466619Z","iopub.status.idle":"2023-11-25T16:59:04.470051Z","shell.execute_reply.started":"2023-11-25T16:59:04.466593Z","shell.execute_reply":"2023-11-25T16:59:04.469207Z"}}},{"cell_type":"code","source":"with strategy.scope():\n    base_model=keras.applications.EfficientNetB7(input_shape=(256,256,3),weights='imagenet',include_top=False)\n    x=Flatten()(base_model.output)\n    x=Dense(512,activation='relu')(x)\n    x=Dense(128,activation=\"relu\")(x)\n    output=Dense(1, activation='sigmoid')(x)\n    model=models.Model(inputs=base_model.input,outputs=output)\n    model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n    model.trainable=False\n    model.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', \n                                        min_delta=0, \n                                        patience=4, \n                                        verbose=0, \n                                        mode='max', \n                                        baseline=None, \n                                        restore_best_weights=True)\n\n# Callback to continuously save the best model after every epoch.\nmodel_checkpoint = ModelCheckpoint(\"efficient_model.h5\", \n                                             monitor='val_accuracy', \n                                             verbose=0, \n                                             save_best_only=False,\n                                             save_weights_only=False, \n                                             mode='max', \n                                             save_freq='epoch')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEPS_PER_EPOCH=len(train_labels) // BATCH_SIZE\nmodel.fit(train_dataset,validation_data=valid_dataset,epochs=5,steps_per_epoch=STEPS_PER_EPOCH,callbacks=[model_checkpoint,early_stopping])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:58:12.150307Z","iopub.execute_input":"2023-12-01T22:58:12.151272Z","iopub.status.idle":"2023-12-01T22:58:12.155030Z","shell.execute_reply.started":"2023-12-01T22:58:12.151237Z","shell.execute_reply":"2023-12-01T22:58:12.154049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict=model.predict(test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(np.round(predict),test_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ConvNetXtLarge","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    base_model=keras.applications.ConvNeXtLarge(input_shape=(256,256,3),weights='imagenet',include_top=False)\n    x=Flatten()(base_model.output)\n    x=Dense(512,activation='relu')(x)\n    x=Dense(128,activation=\"relu\")(x)\n    output=Dense(1, activation='sigmoid')(x)\n    convxnet_model=models.Model(inputs=base_model.input,outputs=output)\n    convxnet_model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n    convxnet_model.trainable=False\n    convxnet_model.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint=ModelCheckpoint(\"convxnet_model.h5\",save_best_only=True)\nSTEPS_PER_EPOCH=len(train_labels) // BATCH_SIZE\nconvxnet_model.fit(train_dataset,validation_data=valid_dataset,epochs=5,steps_per_epoch=STEPS_PER_EPOCH,callbacks=[model_checkpoint])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MobileNet","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    base_model=keras.applications.MobileNetV2(input_shape=(256,256,3),weights='imagenet',include_top=False)\n    x=Flatten()(base_model.output)\n    x=Dense(512,activation='relu')(x)\n    x=Dense(128,activation=\"relu\")(x)\n    output=Dense(1, activation='sigmoid')(x)\n    mobilenet_model=models.Model(inputs=base_model.input,outputs=output)\n    mobilenet_model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n    mobilenet_model.trainable=False\n    mobilenet_model.summary()\nmodel_checkpoint=ModelCheckpoint(\"mobilenet_model.h5\",save_best_only=True)\nSTEPS_PER_EPOCH=len(train_labels)// BATCH_SIZE\nmobilenet_model.fit(train_dataset,validation_data=valid_dataset,epochs=7,steps_per_epoch=STEPS_PER_EPOCH,callbacks=model_checkpoint)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# InceptionResNetV2","metadata":{}},{"cell_type":"code","source":"mobilenet_prediction=mobilenet_model.predict(test)\naccuracy_score(np.round(mobilenet_prediction),test_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    base_model=keras.applications.InceptionResNetV2(input_shape=(256,256,3),weights='imagenet',include_top=False)\n    x=Flatten()(base_model.output)\n    x=Dense(512,activation='relu')(x)\n    x=Dense(128,activation=\"relu\")(x)\n    output=Dense(1, activation='sigmoid')(x)\n    InceptionResNetV2=models.Model(inputs=base_model.input,outputs=output)\n    InceptionResNetV2.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n    InceptionResNetV2.trainable=False\n    InceptionResNetV2.summary()\nmodel_checkpoint=ModelCheckpoint(\"InceptionResNetV2.h5\",save_best_only=True)\nSTEPS_PER_EPOCH=len(train_labels) // BATCH_SIZE\nInceptionResNetV2.fit(train_dataset,validation_data=valid_dataset,epochs=5,steps_per_epoch=STEPS_PER_EPOCH,callbacks=[model_checkpoint])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"InceptionResNetV2_prediction=InceptionResNetV2.predict(test)\naccuracy_score(np.round(InceptionResNetV2_prediction),test_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SRNET","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\n\ndef conv_layer(input_tensor, num_filters, kernel_size, strides, padding='same'):\n    \n    # He initializer\n    filter_initializer = tf.keras.initializers.HeNormal()\n\n    # Bias initializer\n    bias_initializer = tf.keras.initializers.Constant(value=0.2)\n\n    # L2 regularization for the filters\n    filter_regularizer = tf.keras.regularizers.L2(l2=2e-4)\n    \n    x = layers.Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding=padding,\n                  kernel_initializer=filter_initializer,\n                  bias_initializer=bias_initializer,\n                  kernel_regularizer=filter_regularizer,\n                  use_bias=True)(input_tensor)\n    \n    return x\n\n\ndef layer_T1(input_tensor, num_filters):\n    # Convolutional layer\n    x = conv_layer(input_tensor, \n                   num_filters=num_filters, \n                   kernel_size=(3, 3), \n                   strides=1)\n    \n    # Batch normalization layer\n    x = layers.BatchNormalization(momentum=0.9)(x)\n\n    # ReLU activation layer\n    x = layers.ReLU()(x)\n    \n    return x\n\n\ndef layer_T2(input_tensor, num_filters):\n    # Add the layer T1 to the beginning of Layer T2\n    x = layer_T1(input_tensor, num_filters)\n    \n    # Convolutional layer\n    x = conv_layer(x, \n                   num_filters=num_filters, \n                   kernel_size=(3, 3), \n                   strides=1)\n    \n    # Batch normalization layer\n    x = layers.BatchNormalization(momentum=0.9)(x)\n    \n    # Create the residual connection\n    x = layers.add([input_tensor, x]) \n    \n    return x\n\n\ndef layer_T3(input_tensor, num_filters):\n    # MAIN BRANCH\n    # Add the layer T1 to the beginning of Layer T2\n    x = layer_T1(input_tensor, num_filters)\n    \n    # Convolutional layer\n    x = conv_layer(x, \n                   num_filters=num_filters, \n                   kernel_size=(3, 3), \n                   strides=1)\n    \n    # Batch normalization layer\n    x = layers.BatchNormalization(momentum=0.9)(x)\n    \n    # Average pooling layer\n    x = layers.AveragePooling2D(pool_size=(3, 3), \n                                strides=2,\n                                padding='same')(x)\n    \n    # SECONDARY BRANCH\n    # Special convolutional layer. \n    y = conv_layer(input_tensor, \n                   num_filters=num_filters, \n                   kernel_size=(1, 1), \n                   strides=2)\n    \n    # Batch normalization layer\n    y = layers.BatchNormalization(momentum=0.9)(y)\n    \n    # Create the residual connection\n    output = layers.add([x, y]) \n    \n    return output\n\n\ndef layer_T4(input_tensor, num_filters):\n    # Add the layer T1 to the beginning of Layer T2\n    x = layer_T1(input_tensor, num_filters)\n    \n    # Convolutional layer\n    x = conv_layer(x, \n                   num_filters=num_filters, \n                   kernel_size=(3, 3), \n                   strides=1)\n    \n    # Batch normalization layer\n    x = layers.BatchNormalization(momentum=0.9)(x)\n    \n    # Global Average Pooling layer\n    x = layers.GlobalAveragePooling2D()(x)\n    \n    return x\n\n\ndef fully_connected(input_tensor):\n    \n    # Dense weight initializer N(0, 0.01)\n    dense_initializer = tf.random_normal_initializer(0, 0.01)\n    \n    # Bias initializer for the fully connected network\n    bias_dense_initializer = tf.constant_initializer(0.)\n    \n    x = layers.Flatten()(input_tensor)\n    x = layers.Dense(512, \n                     activation=None,\n                     use_bias=False,\n                     kernel_initializer=dense_initializer,\n                     bias_initializer=bias_dense_initializer)(x)\n\n        \n    output = layers.Dense(1, activation='sigmoid')(x)\n    \n    return output\n\n\ndef create_SRNet(input_image_size):\n    # The input layer has the shape (256, 256, 1)\n    input_layer = layers.Input(shape=input_image_size)\n\n    x = layer_T1(input_layer, 64)\n    x = layer_T1(x, 16)\n    \n    x = layer_T2(x, 16)\n    x = layer_T2(x, 16)\n    x = layer_T2(x, 16)\n    x = layer_T2(x, 16)\n    x = layer_T2(x, 16)\n    \n    x = layer_T3(x, 16)\n    x = layer_T3(x, 64)\n    x = layer_T3(x, 128)\n    x = layer_T3(x, 256)\n    \n    x = layer_T4(x, 512)\n    \n    output = fully_connected(x)\n    \n    model = Model(inputs=input_layer, outputs=output, name=\"SRNet\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:40:37.691799Z","iopub.execute_input":"2023-12-01T22:40:37.692682Z","iopub.status.idle":"2023-12-01T22:40:37.708420Z","shell.execute_reply.started":"2023-12-01T22:40:37.692639Z","shell.execute_reply":"2023-12-01T22:40:37.707663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import callbacks\nwith strategy.scope():\n    INPUT_IMAGE_SIZE=(256,256,1)\n    srnet_model = create_SRNet(INPUT_IMAGE_SIZE)\n\n    # Compile the model selecting the loss, the optimizer and the metrics.\n    srnet_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n                  optimizer=optimizers.Adam(learning_rate=0.01),\n                  metrics=['accuracy'])\n    # Callback to stop the algorithm when it doesn't improve.\nearly_stopping = callbacks.EarlyStopping(monitor='val_accuracy', \n                                        min_delta=0, \n                                        patience=3, \n                                        verbose=0, \n                                        mode='max', \n                                        baseline=None, \n                                        restore_best_weights=True)\n\n# Callback to continuously save the best model after every epoch.\nmodel_checkpoint = callbacks.ModelCheckpoint(\"srnet_model.h5\", \n                                             monitor='val_accuracy', \n                                             verbose=0, \n                                             save_best_only=False,\n                                             save_weights_only=False, \n                                             mode='max', \n                                             save_freq='epoch')\n\n    # Callback to change the learning rate after 150 epochs\ndef lr_schedule(epoch):\n    if epoch <= 2:\n        return 0.01\n    else:\n        return 0.001\n\nlearning_rate_scheduler = callbacks.LearningRateScheduler(lr_schedule, verbose=0)\nNUM_EPOCHS = 5\nSTEPS_PER_EPOCH=len(train_labels) // BATCH_SIZE    # Execute the training with all the callbacks\ntrainHistory = srnet_model.fit(train_dataset,\n                         steps_per_epoch=STEPS_PER_EPOCH,\n                         epochs=NUM_EPOCHS, \n                         validation_data=valid_dataset,\n                         callbacks=[early_stopping, model_checkpoint, learning_rate_scheduler])","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:47:25.678883Z","iopub.execute_input":"2023-12-01T22:47:25.679322Z","iopub.status.idle":"2023-12-01T22:56:42.871326Z","shell.execute_reply.started":"2023-12-01T22:47:25.679286Z","shell.execute_reply":"2023-12-01T22:56:42.870079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"srnet_model_prediction=srnet_model.predict(test)\naccuracy_score(np.round(srnet_model_prediction),test_label)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T22:58:21.133832Z","iopub.execute_input":"2023-12-01T22:58:21.134199Z","iopub.status.idle":"2023-12-01T22:58:23.656259Z","shell.execute_reply.started":"2023-12-01T22:58:21.134167Z","shell.execute_reply":"2023-12-01T22:58:23.655357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, epsilon=1e-4, mode='min')\nwith strategy.scope():\n    base_model=keras.applications.xception.Xception(input_shape=(256,256,3),weights='imagenet',include_top=False)\n    x=Flatten()(base_model.output)\n    x=Dense(512,activation='relu')(x)\n    x=Dense(128,activation=\"relu\")(x)\n    output=Dense(1, activation='sigmoid')(x)\n    xception=models.Model(inputs=base_model.input,outputs=output)\n    xception.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n    xception.trainable=False\n    xception.summary()\nmodel_checkpoint=ModelCheckpoint(\"xception.h5\",save_best_only=True)\nSTEPS_PER_EPOCH=len(train_labels) // BATCH_SIZE\nxception.fit(train_dataset,validation_data=valid_dataset,epochs=5,steps_per_epoch=STEPS_PER_EPOCH,callbacks=[model_checkpoint,reduce_lr_loss])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation of Efficientnet","metadata":{}},{"cell_type":"code","source":"def model_input_create(paths):\n    neg_images=[]\n    for path in paths:\n        neg_images.append(decode_image(path))\n    return np.array(neg_images)\n\n\ndef label_creation(predictions):\n    neg_label=[]\n    for i in range(len(predictions)):\n        if predictions[i]>0.5:\n            neg_label.append(1)\n        else:\n            neg_label.append(0)\n    return neg_label","metadata":{"execution":{"iopub.status.busy":"2023-11-27T19:12:05.087739Z","iopub.execute_input":"2023-11-27T19:12:05.088577Z","iopub.status.idle":"2023-11-27T19:12:05.095193Z","shell.execute_reply.started":"2023-11-27T19:12:05.088539Z","shell.execute_reply":"2023-11-27T19:12:05.094168Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load models\nwith strategy.scope():\n    ef_model=keras.models.load_model(\"/kaggle/input/models/efficient_model.h5\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T18:41:41.962441Z","iopub.execute_input":"2023-11-27T18:41:41.962813Z","iopub.status.idle":"2023-11-27T18:43:02.711190Z","shell.execute_reply.started":"2023-11-27T18:41:41.962784Z","shell.execute_reply":"2023-11-27T18:43:02.709728Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_filenames = np.array(os.listdir(\"/kaggle/input/alaska2-image-steganalysis/Cover\"))\nnp.random.seed(0)\npositives = train_filenames.copy()\nnegatives = train_filenames.copy()\nnp.random.shuffle(positives)\nnp.random.shuffle(negatives)\n\njmipod = append_path('JMiPOD')(positives[5000:10000])\njuniward = append_path('JUNIWARD')(positives[10000:15000])\nuerd = append_path('UERD')(positives[15000:20000])\nneg_path = append_path('Cover')(negatives[15000:30000])\npos_path=np.concatenate([jmipod,juniward,uerd])\nnp.random.shuffle(pos_path)\ntrain_paths=np.concatenate([neg_path,pos_path])\nnp.random.shuffle(train_paths)\n\ntrain_labels=[]\nfor path in train_paths:\n    if \"Cover\" in path:\n        train_labels.append(0)\n    else:\n        train_labels.append(1)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T18:43:02.714040Z","iopub.execute_input":"2023-11-27T18:43:02.714353Z","iopub.status.idle":"2023-11-27T18:43:03.307945Z","shell.execute_reply.started":"2023-11-27T18:43:02.714311Z","shell.execute_reply":"2023-11-27T18:43:03.306761Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images=model_input_create(train_paths)\ntrain_pred=ef_model.predict(train_images)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T18:43:03.309190Z","iopub.execute_input":"2023-11-27T18:43:03.309490Z","iopub.status.idle":"2023-11-27T18:48:36.513043Z","shell.execute_reply.started":"2023-11-27T18:43:03.309462Z","shell.execute_reply":"2023-11-27T18:48:36.511867Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#find the number of data points below 0.35\n\nmis_classified=[]\n\nfor path,pred,true in zip(train_paths,train_pred,train_labels):\n    if (pred>0.5) & (true!=1):\n        mis_classified.append(path)\n    if (pred<0.5) & (true!=0):\n        mis_classified.append(path)\nmis_classified=np.concatenate([mis_classified,append_path('JMiPOD')(positives[10000:12000]),append_path('JUNIWARD')(positives[12000:14000]),append_path('UERD')(positives[14000:16000])])\nmis_classified_labels=[]\nfor path in mis_classified:\n    if \"Cover\" in path:\n        mis_classified_labels.append(0)\n    else:\n        mis_classified_labels.append(1)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T18:48:36.516376Z","iopub.execute_input":"2023-11-27T18:48:36.516684Z","iopub.status.idle":"2023-11-27T18:48:36.761717Z","shell.execute_reply.started":"2023-11-27T18:48:36.516654Z","shell.execute_reply":"2023-11-27T18:48:36.760681Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count=0\nfor i in mis_classified_labels:\n    if i==0:\n        count+=1","metadata":{"execution":{"iopub.status.busy":"2023-11-27T18:48:36.762696Z","iopub.execute_input":"2023-11-27T18:48:36.762956Z","iopub.status.idle":"2023-11-27T18:48:36.769218Z","shell.execute_reply.started":"2023-11-27T18:48:36.762929Z","shell.execute_reply":"2023-11-27T18:48:36.768426Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(mis_classified_labels)-count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_validation, y_train, y_validation = train_test_split(mis_classified, mis_classified_labels, test_size=0.15, random_state=1000)\nmisclassified_train_dataset = (tf.data.Dataset\n                 .from_tensor_slices((x_train,y_train))\n                 .map(decode_image, num_parallel_calls=AUTOTUNE)\n                 .cache()\n                 .shuffle(1024)\n                 .batch(BATCH_SIZE)\n                 .prefetch(AUTOTUNE)\n                )\nmisclassified_valid_dataset= (tf.data.Dataset\n                .from_tensor_slices((x_validation,y_validation))\n                .map(decode_image, num_parallel_calls=AUTOTUNE)\n                .batch(BATCH_SIZE)\n                .prefetch(AUTOTUNE)\n\n               )\nearly_stopping = EarlyStopping(monitor='val_accuracy', \n                                        min_delta=0, \n                                        patience=5, \n                                        verbose=0, \n                                        mode='max', \n                                        baseline=None, \n                                        restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T18:48:37.058709Z","iopub.execute_input":"2023-11-27T18:48:37.058972Z","iopub.status.idle":"2023-11-27T18:48:37.165025Z","shell.execute_reply.started":"2023-11-27T18:48:37.058946Z","shell.execute_reply":"2023-11-27T18:48:37.164014Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, epsilon=1e-4, mode='min')\nef_model.fit(misclassified_train_dataset,validation_data=misclassified_valid_dataset,epochs=10,callbacks=[early_stopping,reduce_lr_loss])","metadata":{"execution":{"iopub.status.busy":"2023-11-27T18:48:37.167332Z","iopub.execute_input":"2023-11-27T18:48:37.167634Z","iopub.status.idle":"2023-11-27T19:00:57.080649Z","shell.execute_reply.started":"2023-11-27T18:48:37.167604Z","shell.execute_reply":"2023-11-27T19:00:57.079527Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=ef_model.predict(model_input_create(mis_classified))","metadata":{"execution":{"iopub.status.busy":"2023-11-27T19:00:57.081710Z","iopub.execute_input":"2023-11-27T19:00:57.081981Z","iopub.status.idle":"2023-11-27T19:04:21.612770Z","shell.execute_reply.started":"2023-11-27T19:00:57.081953Z","shell.execute_reply":"2023-11-27T19:04:21.611682Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2023-11-27T19:04:21.614474Z","iopub.execute_input":"2023-11-27T19:04:21.614748Z","iopub.status.idle":"2023-11-27T19:04:21.618537Z","shell.execute_reply.started":"2023-11-27T19:04:21.614721Z","shell.execute_reply":"2023-11-27T19:04:21.617813Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(classification_report(mis_classified_labels,np.round(pred)))","metadata":{"execution":{"iopub.status.busy":"2023-11-27T19:04:21.619413Z","iopub.execute_input":"2023-11-27T19:04:21.619645Z","iopub.status.idle":"2023-11-27T19:04:21.649976Z","shell.execute_reply.started":"2023-11-27T19:04:21.619621Z","shell.execute_reply":"2023-11-27T19:04:21.649177Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nsub = pd.read_csv('/kaggle/input/alaska2-image-steganalysis/sample_submission.csv')\ntest_paths = append_path('Test')(sub.Id.values)\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_files)\n    .map(decode_image, num_parallel_calls=AUTOTUNE)\n    .batch(BATCH_SIZE)\n)\n\nsub.Label=ef_model.predict(test_dataset)\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T19:12:59.744021Z","iopub.execute_input":"2023-11-27T19:12:59.744570Z","iopub.status.idle":"2023-11-27T19:13:05.134377Z","shell.execute_reply.started":"2023-11-27T19:12:59.744533Z","shell.execute_reply":"2023-11-27T19:13:05.133511Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.models.save_model(ef_model,\"efficientnet_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-11-27T19:14:57.464150Z","iopub.execute_input":"2023-11-27T19:14:57.464464Z","iopub.status.idle":"2023-11-27T19:15:06.094308Z","shell.execute_reply.started":"2023-11-27T19:14:57.464434Z","shell.execute_reply":"2023-11-27T19:15:06.093200Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    srnet=keras.models.load_model(\"/kaggle/input/models/srnet_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_accuracy', \n                                        min_delta=0, \n                                        patience=5, \n                                        verbose=0, \n                                        mode='max', \n                                        baseline=None, \n                                        restore_best_weights=True)\nreduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, epsilon=1e-4, mode='min')\nsrnet.fit(train_dataset,validation_data=valid_dataset,epochs=10,callbacks=[early_stopping,reduce_lr_loss],steps_per_epoch=len(x_train)//batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}